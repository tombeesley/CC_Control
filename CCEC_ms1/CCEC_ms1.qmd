---
title: "My Title"
shorttitle: "Short Title in Running Header"
author:
  - name: Jane Doe
    corresponding: true
    orcid: 0000-0000-0000-0001
    email: janedoe@generic.edu
    affiliations:
      - name: Generic University
        department: Department of Scholarly Studies
        address: 1234 Capital St.
        city: New York
        region: NY
        country: USA
        postal-code: 12084-1234
author-note:
  status-changes: 
    affiliation-change: ~
    deceased: ~
  disclosures:
    study-registration: ~
    data-sharing: ~
    related-report: ~
    conflict-of-interest: ~
    financial-support: ~
    gratitude: ~
    authorship-agreements: ~
abstract: "This document is a template."
keywords: [keyword1, keyword2, keyword3]
bibliography: bibliography.bib
format:
  apaquarto-docx: default
  apaquarto-html: default
  apaquarto-pdf:
    documentmode: man
    keep-tex: true
---

@CameronTrivedi2013


```{r}



library(tidyverse)
library(citr)
library(papaja)
library(english)
library(extrafont)
library(afex) 
library(BayesFactor)
library(effectsize)
library(apa)
library(pwr) # power calculations
library(lsr) # effect size estimate
library(patchwork)

# function used to set rounding and presentation of decimals to specific length
spec_dec <- function(x, k) trimws(format(round(x, k), nsmall=k)) # useful for controlling decimals

# function to force scientific formatting of numbers (used for large BFs)
changeSciNot <- function(n) {
  output <- format(n, scientific = TRUE, digits = 2) #Transforms the number into scientific notation even if small
  output <- sub("e", " Ã— 10^", output) #Replace e with 10^
  output <- sub("\\+0?", "", output) #Remove + symbol and leading zeros on exponent, if > 1
  output <- sub("-0?", "-", output) #Leaves - symbol but removes leading zeros on exponent, if < 1
  output <- paste0(output,"^") # makes the exponent superscript
  output
}

#setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set wd to current file location

# function to extract and report BFs with error %s
report_BF_and_error <- function(BF_in, sci_not = TRUE, hyp = "alt"){
  
  if (hyp == "alt") {
    BF_notation = "BF~10~ = "
  } else if (hyp == "null") {
    BF_notation = "BF~01~ = "
  } else if (hyp == "mc") {
    BF_notation = "BF = "
  }
  
  if (sci_not == TRUE) {
    BF_value = changeSciNot(extractBF(BF_in)$bf) # change to sci notation
  } else {
    BF_value = round(extractBF(BF_in)$bf,2) # otherwise round
  }
  
  paste0(BF_notation, 
         BF_value, 
         " &plusmn; ", 
         round(100*extractBF(BF_in)$error,2), 
         "%")
}

# set number of iterations for the Bayesian MC process

numIterations = 50000

```


```{r set_ggplot_theme}

# set global ggplot theme properties

theme_set(theme_classic(base_size = 14))

theme_update(axis.title = element_text(face = "bold", size = 14),
             axis.text = element_text(size = 12),
             legend.text = element_text(size = 12),
             legend.spacing.x = unit(0.4, "cm"))

cbPalette <- c("#C1272D", "#E69F00", "#56B4E9", "#008176", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")



```

It is well established that the process of visual search is guided by past experience. When we encounter a scene, the extent to which the the stimuli within that scene match representations in memory will determine the effectiveness of the processing and subsequent search through the elements of that scene. This cognitive process is studied in the lab using the contextual cuing (CC) task: participants typically experience a standard visual search task (i.e., serial processing; slow search), such as searching for a T amongst L shapes. A set of search configurations is repeated across trials, and response times to targets are faster compared to those in configurations that do not repeat. Thus, the repetition of the search configurations leads to the formation of a representation of the configuration in memory, and future processing of the same configuration activates this representation, driving more efficient behaviour within that scene.

Much work has focused on the nature of the memory and attention processes responsible for contextual cuing. The effect was initially suggested to be implicit in nature, with repeated configurations seemingly guiding search unconsciously: typically participants are unable to articulate their knowledge of the repeated configurations, and show poor ability to recognise learnt configurations in memory tests [e.g., @chun1998; @colagiuri2016], although this view of CC has been strongly contested [e.g., @smyth2008; @vadillo2016]. There are also a number of plausible computational models of how memory representations of repeated configurations are formed and result in the CC effect [e.g., @beesley2015b; @brady2007]. The predominant view is that the memory representations are best characterised as associative in nature, whereby distractors [or groups of distractors, see @beesley2016] form associations that activate more strongly the contingent target position within each repeated configuration.

The exact nature of how repeated configurations come to facilitate visual search is the focus of much debate within the literature. Broadly there are two quite distinct theoretical accounts of why responses are faster for repeated configurations: the early attentional guidance account, and the late response facilitation account. According to the early account, recognition of the configuration leads to a more efficient search process through the distractor array, such that the target is localised (fixated) at an earlier time point in search. Perhaps the clearest (and arguably simplest) evidence in support of this account comes from studies of eye-tracking during CC. For example, search through repeated configurations results in fewer fixations prior to target localisation [e.g., @beesley2018; @tseng2004]. According to the late response facilitation account, the benefit for repeated configurations comes about as a result of enhanced target processing once it has been localised by attention. One conceptualisation of this process is that repeated configurations lead to a reduction in the evidence threshold required to ascertain that the target is present in its location, such that responses can be initiated earlier. Such an account has been put forward by @sewell2018, in order to explain the evidence supporting the late account from response time modelling of the CC effect.

It seems likely that the both early and late processes contribute to the overall CC effect [for a review see @sisk2019]. The current article focuses on exploration of the early-stage attentional account of CC. The term "early" here reflects the fact that the CC benefit is present prior to the detection of the target and the initiation of the response to the target. Analysis of eye-movements has shown that serial visual search can be defined as having two distinct phases: an initial ineffective search in which the direction of saccades is not consistent (arguably random) and a secondary effective phase in which each saccade will draw attention closer to the target. CC appears to result from having more trials with a shorter ineffective phase. 

One interpretation of these data is that CC is initially random, and that the initial distractor processing is not beneficial for CC. Supporting evidence for this account comes from @olson2002, where participants were trained on a CC task in which either all the distractors repeated, those in the half of the screen containing the target (short-range-context), or those in the half of the screen that didn't contain the target (long-range-context). CC was observed in the short-range-context, but not in the long-range-context condition. Thus it would appear that the distractors further from the target are not critical to the generation of a CC effect.

@brady2007's computational account features a mechanism that ensures spatial constraints are placed on the learning of associations with relation to their proximity to the target. If the spatial constraints are tuned to modulate learning and restrict associative formations to only those distractors close to the target, this model can accurately model the data from @olson2002. Since the only consenquential mechanism in the model for CC is the associative weights (and thir modulation by spatial constraints), then one prediction that follows from this account is the the initial phase of search is inconsequential for observing CC. 

The current article provides a test of this prediction by significantly interrupting the search process with an endogenous cue for attention. In all experiments participants complete a contextual cuing visual search task but are also presented with an arrow that signals the side of the screen on which the target will appear. Thus, this cue disrupts the natural search process, eliminating entirely the early phase of search. In contrast to the localised facilitation account, it's possible that contextual cuing involves learning of a procedural template that guides eye-movements in a consistent pattern for each repeated configuration. While the initial process may be inefficient in nature, it may nevertheless be an important part of the procedural response to the configuration in terms of the sequence of eye-movements. Recent data from [Seitz and Geyer] has suggested that 


A number of studies have explored how flexible the learned behaviours are in contextual cuing. For example, a number of studies have shown that moving the target to a new position within the display will abolish the established CC effect [@makovski2011; @manginelli2009]. Notably, @zellin2013 explored the remapping of target positions over a longer training period, observing that with extended training, new associations will form for these new target positions, though the effects are limited to targets that appear closer to those that are initially trained. This suggests that any relocation effect is driven strongly by a generalisation of the pre-existing associations. Furthermore, strong contextual cuing effects were observed for the initially trained targets in a final "return phase" at the end of the experiment. All of these results point towards CC constituting a fairly inflexible behaviour that is activated somewhat automatically during search.

More direct examination of the role of top-down control processes on CC comes from @luque2017b (Experiment 3). They used a task in which participants were initially given a standard CC experiment (search for a T amongst Ls), before then being told in a second phase that the target would appear in two designated positions along the horizontal mid-line of the screen. Participants were given an explicit instruction to search in these two locations for a new target (a Y); in this phase participants engaged in a new search task requiring controlled attention to specified locations. Yet the underlying configuration of repeated distractors was still present, as was the original target, which appeared in its trained location for that configuration. Luque et al. found that the acquired knowledge of the configurations did not affect performance in this second phase: responses to the new target were comparable when the old target was pointed in either the same or opposite direction to the new target, suggesting that there was no detectable processing of the old target [see also @luque2021]. The suggestion is that contextual cuing can be controlled in the presence of a top-down instruction to search in a new location - search is not automatic in nature in the CC task.

One potential issue with the studies presented by Luque and colleagues [@luque2017b; @luque2021] is that participants are instructed to engage in a new search process for a new target object: participants initially search for a T and are later instructed to search for a Y. The role of a prior target template is important for visual search [@vickery2005; @vo2012], and object identities appear to play an important role in the contextual cuing effect [@makovski2017; @makovski2018]. While it is unclear how dependent CC is on the identity of the target, it is possible that distractor-target associations may well be sensitive to target identity and to the goals of the participant. For this reason, the current study assesses the impact of top-down instruction on CC when participants maintain the same task goal of searching for a single target identity within the display.

The overarching aim of the current study is to explore the interaction between controlled (top-down) attentional processes and the pattern of search behaviour established by the repeated configurations. Specifically we seek to understand whether repeated configurations continue to guide attention even when participants are directed to alter their natural search patterns by the presence of an endogenous cue (an arrow that instructs the participant to direct attention in a specific direction). The experiments explore both the performance aspect of CC in terms of whether it continues to guide behaviour once an endogenous cue is introduced, and also whether the development of the search behaviour is impeded when trained concurrently with the endogenous cue.

```{r exploratory_anaysis}

data_raw <- readRDS("combinedData.rds")

# # get summary stats 
# 
# # how many participants in each experiment
# data_raw %>%
#   group_by(exp) %>% 
#   summarise(num_Ps = n_distinct(subj))
# 
# # mean RT by participant
# summary_rt <- 
#   data_raw %>% 
#   filter(timeout == 0,
#          acc == 1) %>% 
#   group_by(exp, subj) %>% 
#   summarise(meanRT = mean(RT))
# 
# # plot as violin
# summary_rt %>% 
#   ggplot(aes(x = exp, y = meanRT)) +
#   geom_violin(aes(fill = exp)) +
#   geom_dotplot(binaxis = "y",
#                stackdir = "center",
#                dotsize = 2,
#                binwidth = 25,
#                alpha = .3)
# 
# # mean acc by participant
# summary_acc <- 
#   data_raw %>% 
#   filter(timeout == 0) %>% 
#   group_by(exp, subj) %>% 
#   summarise(meanAcc = mean(acc))
# 
# # plot as violin
# summary_acc %>% 
#   ggplot(aes(x = exp, y = meanAcc)) +
#   geom_violin(aes(fill = exp)) +
#   geom_dotplot(binaxis = "y",
#                stackdir = "center",
#                binwidth = .01,
#                dotsize = 1,
#                alpha = .3)


```

# Transparency and Openness

The raw data, analysis scripts, experimental materials, and the manuscript source files, are available at <http://github.com/tombeesley/CC_Control>. The analyses reported in this manuscript are computationally reproducible from the manuscript source files (using R v4.3.1), which are available at the github repository. The study design and analyses were not pre-registered.

# Experiment 1

Experiment 1 sought to examine whether the learnt attentional behaviour that develops during contextual cuing is expressed when participants are directed by an endogenous (instructional) cue to search in a particular region of the visual scene. Participants were first trained with a set of four repeating configurations in phase 1 across 5 epochs of 32 trials each. Then prior to phase 2, participants were told that an arrow would appear before every trial indicating the side of the screen on which the target would be located. This arrow was valid on every trial. In phase 2, the repeating configurations were presented in two forms: "consistent", where the target appeared in the same position as it has appeared for that configuration in phase 1; and "inconsistent", where the target appeared in a position in the opposite quadrant of the screen from where it had appeared in phase 1. Random configurations were also presented in this phase. If the contextual cues within the repeated configurations continue to guide attention in the presence of the instructional cue, then we would expect that response times would be faster on consistent trials compared to random trials. In addition, we would also expect that the contextual cues would guide attention *away* from the (new) target quadrant on inconsistent trials, and so response times should be slower on these trials compared to those on random trials.

## Method

### Participants

```{r demographics_exp1}

# get basic stats for Ps

data_exp1 <- 
  data_raw %>% 
  filter(exp == "CCC01")

# rename TT variable
data_exp1 <- 
  data_exp1 %>% 
  mutate(TT = fct_recode(TT, 
                         "Repeated: consistent" = "repeated_con",
                         "Repeated: inconsistent" = "repeated_incon",
                         "Random: consistent" = "random_con",
                         "Random: inconsistent" = "random_incon")) %>% 
  mutate(TT = fct_relevel(TT, 
                          "Repeated: consistent", 
                          "Repeated: inconsistent",
                          "Random: consistent",
                          "Random: inconsistent"))

demographics <- 
  data_exp1 %>% 
  group_by(subj) %>% 
  slice(1) %>% 
  select(subj, age, gender)

```

`r Words(nrow(demographics))` undergraduate students from Lancaster University were recruited (mean age = `r mean(demographics$age)`, SD = `r sd(demographics$age)`; `r sum(demographics$gender=="f")` identified as female and `r sum(demographics$gender=="m")` as female) via the Psychology Research Participation System in the Department of Psychology at Lancaster University, in return for the opportunity to use the recruitment system for their own research in future years.

### Materials

Participants were tested individually in a quiet room with a Dell laptop with a 15.6" screen, a screen resolution of 1920 x 1080, and a full size external keyboard for participants to use to respond to the task. Participants sat approximately 50 cm from the screen. Stimulus presentation was controlled by MATLAB using the Psychophysics Toolbox extensions (Brainard, 1997; Kleiner, Brainard & Pelli, 2007; Pelli, 1997). Responses to the target stimulus were made by pressing the 'c' or 'n' key on a standard keyboard. All experimental materials are available at the github repository for this study.

Distractor stimuli were an 'L' shape (rotated 0Â°, 90Â°, 180Â°, or 270Â°) while the target stimulus was a 'T' shape (rotated at either 90Â° or 270Â°). Stimuli were 8 mm square and arranged in a square grid of 144 evenly spaced cells (12 x 12) which was positioned centrally on the screen and was 170 mm square. The grid itself was invisible to participants. The fixation cross (displayed centrally before each trial) was 4 mm square. The background of the screen was grey (RGB: .6, .6, .6) and the stimuli were presented in black (RGB: 1, 1, 1). There was a small offset in the vertical line of the 'L' distractors, which increased the similarity between the 'L' distractors and the target 'T', making the search task more difficult (Duncan & Humphreys, 1989).

### Design

Phase 1 employed a within-subjects design with factors of epoch (1-5) and configuration (repeated and random). All configurations contained 16 distractors, equally divided between the four quadrants of the display, and one target. Four repeated configurations were trained. Four target locations were used, with one from each quadrant assigned to each of the repeated configurations. These same four target positions were used for the random configurations throughout the task. Each of these four target positions was chosen at random from one of five locations within each quadrant, that were approximately equidistant from the center of the screen. Distractors could not appear in these target locations.

Phase 2 employed a within-subjects design with factors of epoch (6-10) and configuration (repeated: consistent; repeated: inconsistent; random: consistent; random:inconsistent). On each trial, there was a .5 probability that an "inconsistent" version of the configuration would be presented. This meant that the target was relocated to a diametrically opposed target position such as to maximise the displacement from the trained target position (see Figure \@ref(fig:schematicCC)). This could occur for both the repeated and random configurations, hence creating four unique trial types for this phase. While random configurations did not have a "trained", associated, target position, it is necessary to divide the random trials into consistent and inconsistent trial types in this way in order to assess any target frequency effects that may occur, since the inconsistent target locations used in this phase were novel.

(ref:schematicCC) Schematic of the manipulation of target position in consistent and inconsistent trials of phase 2. The dashed lines show the division of the stimuli into quadrants, but were not present in the task procedure.  

- insert schematic here

### Procedure

Participants were tested individually in a quiet testing room. They were given instructions on how to complete the task, including the presentation of an example of a search trial. Participants were shown the two correct responses for the two possible orientations of targets.

Each trial commenced with a fixation cross presented in the center of the screen for 500 ms, which was then replaced immediately by the search configuration. Participants searched for the target stimulus and responded with a left or right response depending on its orientation. Reaction times (RTs) were recorded from the onset of the search configuration. Following a valid response (c or n), the configuration was removed from the screen. The ITI was 1000 ms. If participants made an incorrect response to the target orientation, "INCORRECT RESPONSE" appeared in red in the center of the screen for 3000 ms, prior to the ITI. If participants did not respond within 6000 ms, "TIMEOUT - TOO SLOW" appeared in red in the center of the screen for 3000 ms, prior to the ITI.

Each block of eight trials contained each of the four different repeated configurations and four random configurations. These eight configurations could appear in any order with the constraint that the position of the target did not repeat across trials or across consecutive blocks.

A rest break of 30 seconds was given every 80 trials. Trials started automatically after these breaks.

After 160 trials, prior to phase 2, participants were given an instruction screen which detailed the arrow that would appear on the screen prior to the configuration. They were able to ask any questions they had at this stage and then proceeded to phase 2. The arrow appeared for 1000ms following the fixation cross, before the presentation of the search configuration. The task was otherwise identical to that used in phase 1.

## Results

```{r exclusions_exp1}

# participant exclusions 

to_summary <- 
  data_exp1 %>% 
  group_by(subj) %>% 
  summarise(meanTO = mean(timeout)) %>% 
  mutate(z_meanTO = scale(meanTO)[,1])

acc_summary <- 
  data_exp1 %>% 
  group_by(subj) %>% 
  summarise(meanAcc = mean(acc, na.rm = TRUE)) %>% 
  mutate(z_meanAcc = scale(meanAcc)[,1])

rt_summary <- 
  data_exp1 %>% 
  filter(acc == 1) %>% 
  group_by(subj) %>% 
  summarise(meanRT = mean(RT, na.rm = TRUE)) %>% 
  mutate(z_meanRT = scale(meanRT)[,1])

# combine these into one dataframe
resp_summary_exp1 <- 
  to_summary %>% 
  left_join(acc_summary, by = "subj") %>% 
  left_join(rt_summary, by = "subj")

# is anyone an outlier in terms of timeouts?
outlier_to <- 
  resp_summary_exp1 %>% 
  filter(z_meanTO < -2.5 | z_meanTO > 2.5)

# is anyone an outlier in terms of accuracy?
outlier_acc <- 
  resp_summary_exp1 %>% 
  filter(z_meanAcc < -2.5 | z_meanAcc > 2.5)

# is anyone an outlier in terms of rt?
outlier_rt <- 
  resp_summary_exp1 %>% 
  filter(z_meanRT < -2.5 | z_meanRT > 2.5)

participants_removed <- 
  bind_rows(outlier_to, outlier_acc, outlier_rt) %>% 
  select(subj) %>% 
  mutate(subj = as.character(subj)) %>% 
  unique() %>% 
  pull()



```

Our criterion for removing outlier data, at both the participant level and the trial level, was 2.5 standard deviations above or below the mean of the sample. On average, trials ended with a timeout on `r spec_dec(100*mean(resp_summary_exp1$meanTO),2)`% of trials (SD = `r spec_dec(100*sd(resp_summary_exp1$meanTO),2)`). `r Words(nrow(outlier_to))` participants had an usually high proportion of timeouts and were removed from the analysis. The mean accuracy of participants (not including timeout trials) was `r spec_dec(100*mean(resp_summary_exp1$meanAcc),2)`% (SD = `r spec_dec(100*sd(resp_summary_exp1$meanAcc),2)`%). `r Words(nrow(outlier_acc))` participant had an unusually low proportion of accurate trials and was also removed. The only participant deemed to be an outlier in terms of mean response time (hereafter RT) was also excluded on the basis of the timeout criterion, noted above.

```{r rm_outliers_exp1}

# remove the participant outliers from the data
data_exp1_OR <- 
  data_exp1 %>% 
  filter(!subj %in% participants_removed)

# remove the timeouts and inaccurate trials
data_exp1_OR <- 
  data_exp1_OR %>% 
  filter(timeout == 0,
         acc == 1) %>% 
  group_by(subj) %>% 
  mutate(zRT = scale(RT)[,1]) # calculate z scores on participant basis

# get a summary of the RT outlier removal
rt_outlier_summary <- 
  data_exp1_OR %>% 
  group_by(subj) %>% 
  summarise(prop_rem = mean(zRT < -2.5 | zRT > 2.5))

# was anyone an outlier in prop removed?
outlier_prop_removed <- 
  rt_outlier_summary %>% 
  mutate(z_prop_rem = scale(prop_rem)[,1]) %>% 
  filter(z_prop_rem < -2.5 | z_prop_rem > 2.5)

# remove the outlier RTs from the data 
data_e1_f <-
  data_exp1_OR %>%
  ungroup() %>%
  filter(zRT > -2.5 & zRT < 2.5) # keep data in this range

```

For the remaining `r words(nrow(rt_outlier_summary))` participants we removed trials with a timeout and inaccurate trials, before removing outliers from the RT data. On average, the proportion of outliers removed was `r spec_dec(100*mean(rt_outlier_summary$prop_rem),2)`% (SD = `r spec_dec(100*sd(rt_outlier_summary$prop_rem),2)`%). `r Words(nrow(outlier_prop_removed))` participants had an unusual proportion of trials removed as outlier RTs (greater than 2.5 SDs above the mean).

```{r rt_summary_exp1}
# compute grand mean RT 
grand_mean_e1 <- mean(data_e1_f$RT)

# create subj level mean and normalised RT variable
data_e1_f <- 
  data_e1_f %>%
  group_by(subj) %>% 
  mutate(subj_mean_rt = mean(RT),
         normRT = RT - subj_mean_rt + grand_mean_e1) %>% 
  select(-subj_mean_rt)

# summarise the data across the 10 epochs, by subj
rt_summary_data_e1 <- 
  data_e1_f %>% 
  group_by(subj, epoch, TT) %>% 
  summarise(meanRT = mean(RT),
            mean_norm_RT = mean(normRT)) # used for normalised SE bars

# # explore whether all Ps showed reduction in RTs phase 1 to phase 2 - yes they did
# data_e1_f %>% 
#   filter(epoch %in% c(4:7),
#          acc == 1) %>% 
#   group_by(subj, epoch) %>%
#   summarise(meanRT = mean(RT)) %>% 
#   pivot_wider(names_from = epoch, names_prefix = "epoch_", values_from = meanRT) %>% 
#   rowwise() %>% 
#   mutate(drop_in_RT = mean(c(epoch_4,epoch_5)) - mean(c(epoch_6,epoch_7)))

```

(ref:Exp1-RT-figure) RT data for Experiment 1. The phase 2 averages across the four trial types are shown inset. Within-subject error bars were computed by a process of normalising the RT data for the sample [@cousineau2005].

Figure \@ref(fig:Exp1-RT-figure) shows the RT data across the 10 epochs of the experiment. In phase 1 (epochs 1-5) a contextual cuing effect emerged, with faster responses to repeated over random configurations. In phase 2, the presence of the guiding arrow led to a clear reduction in the response times. For all participants, the mean RT across epochs 4 and 5 was higher than the mean RTs across epochs 6 and 7. Despite the clear evidence for the processing of the endogenous cue, the underlying search configuration continued to play a role in the guidance of attention, with faster response times for (consistent) repeated configurations compared to random configurations.

```{r }

# factorLbls <- c("Repeated: Consistent", "Random: Consistent", "Repeated: Inconsistent", "Random: Inconsistent")
# 
# # summarise at the group level and plot
# rt_all_exp1 <- 
#   rt_summary_data_e1 %>% 
#   separate(TT, into = c("config", "targ_pos"), sep = ": ") %>%   # split the TT into factors of Config and target consistency
#   mutate(config = as.factor(fct_relevel(config, "Repeated", "Random")),
#          targ_pos = as.factor(fct_relevel(targ_pos, "consistent", "inconsistent")))
#   
#   
# rf_fig_exp1 <- 
#   rt_all_exp1 %>%   
#   group_by(epoch, config, targ_pos) %>% 
#   summarise(group_RT = mean(meanRT),
#             group_SE = sd(mean_norm_RT)/sqrt(n())) %>% 
#   ggplot(aes(x = epoch, y = group_RT)) +
#   geom_line(aes(group = interaction(config, targ_pos)), size = .5) +
#   geom_errorbar(aes(ymin = group_RT - group_SE,
#                     ymax = group_RT + group_SE),
#                 width = .2,
#                 size = .5) +
#   geom_point(aes(fill = interaction(config, targ_pos),
#                  shape = interaction(config, targ_pos)), size = 5) +
#   labs(y = "RT (ms)",
#        x = "Epochs of 32 trials") +
#   scale_fill_manual(name = "",
#                     labels = factorLbls,
#                     values= c(cbPalette[c(1,3)],c(cbPalette[c(1,3)]))) +
#   scale_shape_manual(name = "",
#                      labels = factorLbls,
#                      values = c(21,21,22,22)) +
#   theme(legend.position = c(0.25,.25),
#         legend.direction = "vertical") +
#   guides(fill = guide_legend(byrow = TRUE)) +
#   scale_y_continuous(limits = c(1000, 2400), breaks = seq(1000, 2400, 200))
# 
# phase2_avg_col <- 
#   rt_all_exp1 %>% 
#   filter(epoch %in% c(6:10)) %>% 
#   group_by(config, targ_pos) %>% 
#   summarise(group_RT = mean(meanRT),
#             group_SE = sd(mean_norm_RT)/sqrt(n())) %>% 
#   ggplot(aes(x = config, y = group_RT, fill = targ_pos)) +
#   geom_errorbar(aes(ymin = group_RT,
#                     ymax = group_RT + group_SE),
#                 width = .2,
#                 size = .5,
#                 position = position_dodge(.8)) +
#   geom_col(colour = "black", size = 0.5, width = .8, position = position_dodge()) +
#   scale_fill_manual(name = "",
#                     labels = c("Consistent", "Inconsistent"),
#                     values= c(cbPalette[c(1,3)],c(cbPalette[c(1,3)]))) +
#   coord_cartesian(ylim = c(1200,1600)) +
#   theme(plot.title = element_text(size = 10, hjust = 0.5, face = "bold"),
#         plot.background = element_rect(fill = "#f2f2f2", colour = "black"),
#         panel.background = element_rect(fill = "#f2f2f2"),
#         legend.position = c(0.5,0.9),
#         legend.background = element_blank(),
#         legend.direction = "vertical",
#         legend.text = element_text(size = 8),
#         legend.key.size = unit(0.4, "cm"),
#         axis.title.x = element_blank(),
#         axis.text.x = element_text(size = 8),
#         axis.text.y = element_text(size = 8),
#         axis.title.y = element_text(size = 10)) +
#   labs(y = "RT (ms)",
#        title = "Phase 2 averages")
# 
# rf_fig_exp1 + inset_element(phase2_avg_col, 0.55, 0.5, 1, 1)

```

```{r phase_1_BFs_exp1}
# Experiment 1 stats

# Statistics on Phase 1

phase_1 <- 
  rt_summary_data_e1 %>% 
  mutate(epoch = as.factor(epoch)) %>% 
  filter(epoch %in% c(1:5))



e1_phase1_BF <- 
  anovaBF(meanRT ~ TT * epoch + subj, 
          data = phase_1,
          whichRandom = "subj",
          iterations = numIterations)

# computing effect sizes
e1_phase1_ES <- effectsize::eta_squared(aov_car(meanRT ~ Error(subj/TT*epoch), data = phase_1), 
                                        partial = TRUE)


```

These data were analysed with a Bayesian ANOVA[^1], using the *BayesFactor::anovaBF()* function in R. All analyses in this study used the default parameters for the priors, which "places mass in reason-able ranges [of effect sizes] without being overcommitted to any one point" [@rouder2017, p. 317]. First taking the data from phase 1 (epochs 1-5), there was strong support for the model containing the factors of epoch and configuration (repeated vs. random), `r report_BF_and_error(e1_phase1_BF[3])`. The addition of the interaction term did not improve the model fit, `r report_BF_and_error(e1_phase1_BF[4]/e1_phase1_BF[3], sci_not = FALSE, hyp = "mc")`, though there was no evidence for the absence of the interaction. The best fitting model was a better fit than the two models containing only one of the factors, smallest `r report_BF_and_error(e1_phase1_BF[3]/e1_phase1_BF[1], sci_not = FALSE, hyp = "mc")`, providing strong support for both the effects of configuration and epoch. Partial eta-squared ($n^2_p$) effect sizes were calculated using *effectsize::eta_squared*, giving values of: `r e1_phase1_ES[1,2]` for the effect of configuration; `r e1_phase1_ES[2,2]` for the effect of epoch; and `r e1_phase1_ES[3,2]` for the interaction effect.

[^1]: The Bayesian analyses here follow the process outlined in @rouder2017. Briefly, we present the best fitting model evaluated against the null model, and then compare this fit to that of other models. Where the comparison of two models (i.e., A against B) reveals a Bayes Factor of greater than 3, this is taken as support for the components of model A that are not present in model B. Bayes Factors of less than 0.33 are taken as evidence in support of the equivalence of two models. Following @wetzels2011a we use the terms "substantial" (BF>3; BF<1/3), and "strong" (BF>10; BF<1/10) to reflect the levels of support for the results of the model comparisons. 

```{r phase_2_BFs_exp1}
# Experiment 1 stats

# Statistics on Phase 2

phase_2 <- 
  rt_summary_data_e1 %>% 
  mutate(epoch = as.factor(epoch)) %>% 
  filter(epoch %in% c(6:10)) %>% 
  separate(TT, into = c("config", "targ_pos"), sep = ": ") %>%   # split the TT into factors of Config and target consistency
  mutate(config = as.factor(config),
         targ_pos = as.factor(targ_pos))

e1_phase2_BF <- 
  anovaBF(meanRT ~ config * targ_pos * epoch + subj, 
          data = phase_2,
          whichRandom = "subj",
          iterations = numIterations)

exp1_ttestBF_data <- 
  rt_summary_data_e1 %>% 
  mutate(epoch = as.factor(epoch)) %>% 
  filter(epoch %in% c(6:10)) %>% 
  group_by(subj, TT) %>% 
  summarise(meanRT=mean(meanRT)) %>% 
  pivot_wider(values_from = meanRT, names_from = TT) %>% 
  janitor::clean_names()

exp1_p2_repC_randC <- ttestBF(x = exp1_ttestBF_data$repeated_consistent, 
                              y = exp1_ttestBF_data$random_consistent, 
                              paired = TRUE, 
                              iterations = numIterations)

exp1_p2_repI_randI <- ttestBF(x = exp1_ttestBF_data$repeated_inconsistent, 
                              y = exp1_ttestBF_data$random_inconsistent,
                              paired = TRUE, 
                              iterations = numIterations)

exp1_p2_repC_repI <- ttestBF(x = exp1_ttestBF_data$repeated_consistent, 
                             y = exp1_ttestBF_data$repeated_inconsistent, 
                             paired = TRUE, 
                             iterations = numIterations)

# computing effect sizes
e1_phase2_ES <- effectsize::eta_squared(aov_car(meanRT ~ Error(subj/config*targ_pos), 
                                                data = phase_2), 
                                        partial = TRUE)


```

A Bayesian ANOVA on the data from phase 2 (epochs 6-10) found strong support for the model containing the factors of configuration (repeated vs. random) and target position (consistent vs. inconsistent), `r report_BF_and_error(e1_phase2_BF[7], sci_not = FALSE)`. The next best fitting model contained these two factors and the interaction term, and was not a substantially worse fit to the data, `r report_BF_and_error(e1_phase2_BF[13]/e1_phase2_BF[7], sci_not = FALSE, hyp = "mc")`. The best fitting model (with factors of configuration and target position, but no interaction) was a substantially better fit to the data than the model containing only the factor of configuration `r report_BF_and_error(e1_phase2_BF[7]/e1_phase2_BF[2], sci_not = FALSE, hyp = "mc")` providing evidence that RTs were faster on consistent than inconsistent trials. There was no evidence for a difference between the best fitting model and the model containing only the factor of target position, `r report_BF_and_error(e1_phase2_BF[7]/e1_phase2_BF[5], sci_not = FALSE, hyp = "mc")`. The relevant effect sizes ($n^2_p$) were: `r e1_phase2_ES[1,2]` for the effect of configuration; `r e1_phase2_ES[2,2]` for the effect of target position; and `r e1_phase2_ES[3,2]` for the interaction of these two factors.

To further explore responses to the different trial types in phase 2, Bayesian t-tests were run using BayesFactor::ttestBF (using the default Cauchy prior) for comparisons between the repeated and random configurations, across the two target position conditions (consistent and inconsistent). This revealed substantial support for a difference between the response times on "repeated: consistent" trials and those on the respective random trials (random: consistent), `r report_BF_and_error(exp1_p2_repC_randC, sci_not = FALSE)`. There was also substantial evidence to suggest there was no meaningful difference between the response times for the "repeated: inconsistent" trials and the respective random trials, `r report_BF_and_error(exp1_p2_repI_randI, sci_not = FALSE)`. 

## Discussion

Experiment 1 sought to examine the consequence of an endogenous cue that prompts top-down control of the search process on contextual cuing. In phase 1 we established a robust contextual cuing effect. Following this, participants received instruction that each trial would be preceded by an arrow stimulus that would signal the side of the screen on which the target would appear. This cue was valid on all trials in phase 2. Consistent with these instructions and the processing of this cue, we observed substantially reduced search times in phase 2 compared to phase 1. The same set of repeated configurations were presented in phase 2, but for half of the trials, the target was relocated to the diagonally opposed quadrant of the screen. Therefore, on these "repeated inconsistent" trials, the underlying configuration of distractors predicted the target in a location that opposed that of the (valid) endogenous cue. Across this phase we observed significant contextual cuing for the repeated consistent trials, demonstrating that the underlying configuration of distractors continued to guide attention in the presence of the endogenous cue. However, the repeated inconsistent trials did not lead to an impairment in response times relative to random trials, suggesting that the underlying configuration did not influence search on these trials.


<!-- References will auto-populate in the refs div below -->

::: {#refs}
:::

# Appendix

# Title for Appendix
